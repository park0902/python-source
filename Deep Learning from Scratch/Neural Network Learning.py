'''
--------------------------------------------------------------------------------------
- 학습

    훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것

    
- 손실함수

    신경망이 학습할 수 있도록 해주는 지표(평균 제곱 오차, 교차 엔트로피 오차 사용)
    
=> 손실함수의 결과값을 가장 작게 만드는 가중치 매개변수를 찾는 것이 목표!!!


- 오버피팅

    한 데이터셋에만 지나치게 최적화된 상태
--------------------------------------------------------------------------------------
'''

'''
--------------------------------------------------------------------------------------
- 평균 제곱 오차

          1
    E =  --- 시그마 (yk - tk)의 제곱
          2
          
        
        yk : 신경망의 출력(신경망이 추정한 값)
        tk : 정답 레이블
        k : 데이터의 차원 수
--------------------------------------------------------------------------------------
'''

import numpy as np

def mean_squared_error(y, t):
    return 0.5 * np.sum((y-t) ** 2)

t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]
y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]
y1 = [0.1 ,0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]

print(mean_squared_error(np.array(y), np.array(t)))     # 정답도 2이고, 신경망의 출력도 2   0.0975....
print(mean_squared_error(np.array(y1), np.array(t)))    # 정답은 2이고, 신경망의 출력은 7   0.5975.....

# 평균 제곱 오차를 기준으로 오차가 더 작은 값이 정답에 가까울 것으로 판단!!!



'''
--------------------------------------------------------------------------------------
- 교차 엔트로피 오차

          
    E =  - 시그마 (tk * log yk)
          


        yk : 신경망의 출력(신경망이 추정한 값)
        tk : 정답 레이블
        k : 데이터의 차원 수
--------------------------------------------------------------------------------------
'''

def cross_entropy_error(y, t):
    delta = 1e-7
    return -np.sum(t * np.log(y + delta))

t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]
y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]
y1 = [0.1 ,0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]

print(cross_entropy_error(np.array(y), np.array(t)))    # 정답일때 출력이 0.6인경우 교차 엔트로피 오차는 약 0.51
print(cross_entropy_error(np.array(y1), np.array(t)))   # 정답일때 출력이 0.1인경우 교차 엔트로피 오차는 무려 2.3

# 오차 값이 더 작은 첫 번째 추정이 정답일 가능성이 높다고 판단한 것으로 앞서 평균 제곱 오차의 판단과 일치!!!




'''
--------------------------------------------------------------------------------------
- 미니배치 학습

    가령 60000장의 훈련 데이터 중에서 100장을 무작위로 뽑아 그 100장만을 사용하여 학습하는 것
    이러한 학습 방법을 미니배치 학습이라고 한다!!!


    기계학습 문제
    
        훈련 데이터에 대한 손실 함수의 값을 구하고, 그 값을 최대한 줄여주는 매개변수를 찾아낸다!
        
        모든 훈련 데이터를 대상으로 손실 함수의 값을 구해야 한다!!!
        
    
    교차 엔트로피 오차
    
                  1  
        E  =  - ----- 시그마(n) 시그마(k) * tnk * log ynk
                  N
                  
                  
        데이터가 N개라면   tnk : n 번째 데이터의 k번째 값(정답 레이블)
                        ynk : 신경망의 출력
--------------------------------------------------------------------------------------
'''

import  sys, os
sys.path.append(os.pardir)
import numpy as np
from MNIST import  load_mnist

(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)

print(x_train.shape)    # (60000, 784)
print(t_train.shape)    # (60000, 10)

# 훈련데이터는 60000개, 입력데이터는 784열(원래 28 X 28)인 이미지 데이터
# 정답 레이블은 10줄짜리 데이터
